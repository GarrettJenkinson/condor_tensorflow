<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Garrett Jenkinson">
  <link rel="canonical" href="http://GarrettJenkinson.github.io/condor_tensorflow/tutorials/poker/">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Poker Hands - condor_tensorflow</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  <link href="../../extra.css" rel="stylesheet" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Poker Hands";
    var mkdocs_page_input_path = "tutorials/poker.md";
    var mkdocs_page_url = "/condor_tensorflow/tutorials/poker/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> condor_tensorflow</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Tutorials</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../amazon/">Amazon Reveiews</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../mnist/">MNIST</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Poker Hands</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#0-obtaining-and-preparing-the-poker-hand-dataset-from-the-uci-ml-repository">0 -- Obtaining and preparing the Poker Hand dataset from the UCI ML repository</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#1-setting-up-the-dataset-and-dataloader">1 -- Setting up the dataset and dataloader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-equipping-mlp-with-condor-layer">2 - Equipping MLP with CONDOR layer</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-using-the-condor-loss-for-model-training">3 - Using the CONDOR loss for model training</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-evaluate-model">4 -- Evaluate model</a>
    </li>
    </ul>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../installation/">Installation</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../CHANGELOG/">Changelog</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../citing/">Citing</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../license/">License</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">API</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_subpackages/condor_tensorflow.loss/">condor_tensorflow.loss</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_subpackages/condor_tensorflow.metrics/">condor_tensorflow.metrics</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_subpackages/condor_tensorflow.activations/">condor_tensorflow.activations</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_subpackages/condor_tensorflow.labelencoder/">condor_tensorflow.labelencoder</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.labelencoder/BaseEstimator/">condor_tensorflow.labelencoder.BaseEstimator</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.labelencoder/CondorOrdinalEncoder/">condor_tensorflow.labelencoder.CondorOrdinalEncoder</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.labelencoder/OrdinalEncoder/">condor_tensorflow.labelencoder.OrdinalEncoder</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.labelencoder/TransformerMixin/">condor_tensorflow.labelencoder.TransformerMixin</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.loss/CondorOrdinalCrossEntropy/">condor_tensorflow.loss.CondorOrdinalCrossEntropy</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.loss/SparseCondorOrdinalCrossEntropy/">condor_tensorflow.loss.SparseCondorOrdinalCrossEntropy</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.loss/OrdinalEarthMoversDistance/">condor_tensorflow.loss.OrdinalEarthMoversDistance</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.loss/SparseOrdinalEarthMoversDistance/">condor_tensorflow.loss.SparseOrdinalEarthMoversDistance</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.metrics/OrdinalMeanAbsoluteError/">condor_tensorflow.metrics.OrdinalMeanAbsoluteError</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.metrics/SparseOrdinalMeanAbsoluteError/">condor_tensorflow.metrics.SparseOrdinalMeanAbsoluteError</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.metrics/OrdinalAccuracy/">condor_tensorflow.metrics.OrdinalAccuracy</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../api_modules/condor_tensorflow.metrics/SparseOrdinalAccuracy/">condor_tensorflow.metrics.SparseOrdinalAccuracy</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">condor_tensorflow</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Tutorials &raquo;</li>
        
      
    
    <li>Poker Hands</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/GarrettJenkinson/condor_tensorflow/edit/master/docs/tutorials/poker.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h1 id="condor-mlp-for-predicting-poker-hands-needs-converting-to-tensorflow">CONDOR MLP for predicting poker hands NEEDS CONVERTING TO TENSORFLOW</h1>
<p>This tutorial explains how to equip a deep neural network with the CONDOR layer and loss function for ordinal regression in the context of predicting poker hands.</p>
<h2 id="0-obtaining-and-preparing-the-poker-hand-dataset-from-the-uci-ml-repository">0 -- Obtaining and preparing the Poker Hand dataset from the UCI ML repository</h2>
<p>First, we are going to download and prepare the UCI Poker Hand dataset from <a href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand">https://archive.ics.uci.edu/ml/datasets/Poker+Hand</a> and save it as CSV files locally. This is a general procedure that is not specific to CONDOR.</p>
<p>This dataset has 10 ordinal labels, </p>
<pre><code>0: Nothing in hand; not a recognized poker hand 
1: One pair; one pair of equal ranks within five cards 
2: Two pairs; two pairs of equal ranks within five cards 
3: Three of a kind; three equal ranks within five cards 
4: Straight; five cards, sequentially ranked with no gaps 
5: Flush; five cards with the same suit 
6: Full house; pair + different rank three of a kind 
7: Four of a kind; four equal ranks within five cards 
8: Straight flush; straight + flush 
9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush 
</code></pre>
<p>where 0 &lt; 1 &lt; 2 ... &lt; 9.</p>
<p>Download training examples and test dataset:</p>
<pre><code class="language-python">import pandas as pd


train_df = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data&quot;, header=None)
train_features = train_df.loc[:, 0:10]
train_labels = train_df.loc[:, 10]

print('Number of features:', train_features.shape[1])
print('Number of training examples:', train_features.shape[0])
</code></pre>
<pre><code>Number of features: 11
Number of training examples: 25010
</code></pre>
<pre><code class="language-python">test_df = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data&quot;, header=None)
test_df.head()

test_features = test_df.loc[:, 0:10]
test_labels = test_df.loc[:, 10]

print('Number of test examples:', test_features.shape[0])
</code></pre>
<pre><code>Number of test examples: 1000000
</code></pre>
<p>Standardize features:</p>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler


sc = StandardScaler()
train_features_sc = sc.fit_transform(train_features)
test_features_sc = sc.transform(test_features)
</code></pre>
<p>Save training and test set as CSV files locally</p>
<pre><code class="language-python">pd.DataFrame(train_features_sc).to_csv('train_features.csv', index=False)
train_labels.to_csv('train_labels.csv', index=False)

pd.DataFrame(test_features_sc).to_csv('test_features.csv', index=False)
test_labels.to_csv('test_labels.csv', index=False)

# don't need those anymore
del test_features
del train_features
del train_labels
del test_labels
</code></pre>
<h2 id="1-setting-up-the-dataset-and-dataloader">1 -- Setting up the dataset and dataloader</h2>
<p>In this section, we set up the data set and data loaders using PyTorch utilities. This is a general procedure that is not specific to CONDOR.</p>
<pre><code class="language-python">import torch


##########################
### SETTINGS
##########################

# Hyperparameters
random_seed = 1
learning_rate = 0.001
num_epochs = 20
batch_size = 128

# Architecture
NUM_CLASSES = 10

# Other
DEVICE = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
print('Training on', DEVICE)
</code></pre>
<pre><code>Training on cpu
</code></pre>
<pre><code class="language-python">from torch.utils.data import Dataset
import numpy as np


class MyDataset(Dataset):

    def __init__(self, csv_path_features, csv_path_labels, dtype=np.float32):

        self.features = pd.read_csv(csv_path_features).values.astype(np.float32)
        self.labels = pd.read_csv(csv_path_labels).values.flatten()

    def __getitem__(self, index):
        inputs = self.features[index]
        label = self.labels[index]
        return inputs, label

    def __len__(self):
        return self.labels.shape[0]
</code></pre>
<pre><code class="language-python">import torch
from torch.utils.data import DataLoader


# Note transforms.ToTensor() scales input images
# to 0-1 range
train_dataset = MyDataset('train_features.csv', 'train_labels.csv')
test_dataset = MyDataset('test_features.csv', 'test_labels.csv')


train_loader = DataLoader(dataset=train_dataset,
                          batch_size=batch_size,
                          shuffle=True, # want to shuffle the dataset
                          num_workers=0) # number processes/CPUs to use

test_loader = DataLoader(dataset=test_dataset,
                         batch_size=batch_size,
                         shuffle=True, # want to shuffle the dataset
                         num_workers=0) # number processes/CPUs to use

# Checking the dataset
for inputs, labels in train_loader:  
    print('Input batch dimensions:', inputs.shape)
    print('Input label dimensions:', labels.shape)
    break
</code></pre>
<pre><code>Input batch dimensions: torch.Size([128, 11])
Input label dimensions: torch.Size([128])
</code></pre>
<h2 id="2-equipping-mlp-with-condor-layer">2 - Equipping MLP with CONDOR layer</h2>
<p>In this section, we are using the CondorLayer implemented in <code>condor_pytorch</code> to outfit a multilayer perceptron for ordinal regression. Note that the CONDOR method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CONDOR layer.</p>
<p>Also, please use the <code>sigmoid</code> not softmax function (since the CONDOR method uses a concept known as extended binary classification as described in the paper).</p>
<pre><code class="language-python">from condor_pytorch.layers import CondorLayer



class CondorMLP(torch.nn.Module):

    def __init__(self, num_classes):
        super(CondorMLP, self).__init__()

        self.features = torch.nn.Sequential(
            torch.nn.Linear(11, 5),
            torch.nn.Linear(5, 5))

        ### Specify CONDOR layer
        self.fc = CondorLayer(size_in=5, num_classes=num_classes)
        ###--------------------------------------------------------------------###

    def forward(self, x):
        x = self.features(x)

        ##### Use CONDOR layer #####
        logits =  self.fc(x)
        probas = torch.sigmoid(logits)
        ###--------------------------------------------------------------------###

        return logits, probas



torch.manual_seed(random_seed)
model = CondorMLP(num_classes=NUM_CLASSES)
model.to(DEVICE)

optimizer = torch.optim.Adam(model.parameters())
</code></pre>
<h2 id="3-using-the-condor-loss-for-model-training">3 - Using the CONDOR loss for model training</h2>
<p>During training, all you need to do is to </p>
<p>1) convert the integer class labels into the extended binary label format using the <code>levels_from_labelbatch</code> provided via <code>condor_pytorch</code>:</p>
<pre><code class="language-python">        levels = levels_from_labelbatch(class_labels, 
                                        num_classes=NUM_CLASSES)
</code></pre>
<p>2) Apply the CONDOR loss (also provided via <code>condor_pytorch</code>):</p>
<pre><code class="language-python">        cost = condor_loss(logits, levels)
</code></pre>
<pre><code class="language-python">from condor_pytorch.dataset import levels_from_labelbatch
from condor_pytorch.losses import condor_loss


for epoch in range(num_epochs):

    model = model.train()
    for batch_idx, (features, class_labels) in enumerate(train_loader):

        ##### Convert class labels for CONDOR
        levels = levels_from_labelbatch(class_labels, 
                                        num_classes=NUM_CLASSES)
        ###--------------------------------------------------------------------###

        features = features.to(DEVICE)
        levels = levels.to(DEVICE)
        logits, probas = model(features)

        #### CONDOR loss 
        cost = condor_loss(logits, levels)
        ###--------------------------------------------------------------------###   


        optimizer.zero_grad()
        cost.backward()
        optimizer.step()

        ### LOGGING
        if not batch_idx % 200:
            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' 
                   %(epoch+1, num_epochs, batch_idx, 
                     len(train_loader), cost))
</code></pre>
<pre><code>Epoch: 001/020 | Batch 000/196 | Cost: 6.5905
Epoch: 002/020 | Batch 000/196 | Cost: 3.0309
Epoch: 003/020 | Batch 000/196 | Cost: 1.7885
Epoch: 004/020 | Batch 000/196 | Cost: 1.2904
Epoch: 005/020 | Batch 000/196 | Cost: 1.2604
Epoch: 006/020 | Batch 000/196 | Cost: 1.3774
Epoch: 007/020 | Batch 000/196 | Cost: 1.0882
Epoch: 008/020 | Batch 000/196 | Cost: 1.1178
Epoch: 009/020 | Batch 000/196 | Cost: 1.0749
Epoch: 010/020 | Batch 000/196 | Cost: 1.0276
Epoch: 011/020 | Batch 000/196 | Cost: 0.9430
Epoch: 012/020 | Batch 000/196 | Cost: 0.9547
Epoch: 013/020 | Batch 000/196 | Cost: 0.7979
Epoch: 014/020 | Batch 000/196 | Cost: 0.9496
Epoch: 015/020 | Batch 000/196 | Cost: 0.6845
Epoch: 016/020 | Batch 000/196 | Cost: 0.9132
Epoch: 017/020 | Batch 000/196 | Cost: 0.8270
Epoch: 018/020 | Batch 000/196 | Cost: 0.6653
Epoch: 019/020 | Batch 000/196 | Cost: 0.6094
Epoch: 020/020 | Batch 000/196 | Cost: 0.7930
</code></pre>
<h2 id="4-evaluate-model">4 -- Evaluate model</h2>
<p>Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures.</p>
<p>For this, we are going to use the <code>proba_to_label</code> utility function from <code>condor_pytorch</code> to convert the probabilities back to the orginal label.</p>
<pre><code class="language-python">from condor_pytorch.dataset import proba_to_label


def compute_mae_and_mse(model, data_loader, device):

    with torch.no_grad():

        mae, mse, acc, num_examples = 0., 0., 0., 0

        for i, (features, targets) in enumerate(data_loader):

            features = features.to(device)
            targets = targets.float().to(device)

            logits, probas = model(features)
            predicted_labels = proba_to_label(probas).float()

            num_examples += targets.size(0)
            mae += torch.sum(torch.abs(predicted_labels - targets))
            mse += torch.sum((predicted_labels - targets)**2)

        mae = mae / num_examples
        mse = mse / num_examples
        return mae, mse
</code></pre>
<pre><code class="language-python">train_mae, train_mse = compute_mae_and_mse(model, train_loader, DEVICE)
test_mae, test_mse = compute_mae_and_mse(model, test_loader, DEVICE)
</code></pre>
<pre><code class="language-python">print(f'Mean absolute error (train/test): {train_mae:.2f} | {test_mae:.2f}')
print(f'Mean squared error (train/test): {train_mse:.2f} | {test_mse:.2f}')
</code></pre>
<pre><code>Mean absolute error (train/test): 0.10 | 0.10
Mean squared error (train/test): 0.21 | 0.21
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../installation/" class="btn btn-neutral float-right" title="Installation">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../mnist/" class="btn btn-neutral" title="MNIST"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2021 <a href="http://github.com/GarrettJenkinson">Garrett Jenkinson</a></p>
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/GarrettJenkinson/condor_tensorflow/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../mnist/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../installation/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" defer></script>
      <script src="../../mathjaxhelper.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
