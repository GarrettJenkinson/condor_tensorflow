{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CONDOR TensorFlow demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcT_VpWpT1Kf"
      },
      "source": [
        "# CONDOR Ordinal classification/regression in Tensorflow Keras \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GarrettJenkinson/condor_tensorflow/blob/main/docs/CONDOR_TensorFlow_demo.ipynb)\n",
        "\n",
        "\n",
        "This notebook uses MNIST hand-written digits and Amazon reviews as a examples of ordinal classification, using the condor_tensorflow package for Tensorflow Keras.\n",
        "\n",
        "\n",
        "**Acknowledgments**: This notebook is based in part on PyTorch source code written by Sebastian Rashka [in this notebook](https://github.com/Raschka-research-group/coral-cnn/blob/master/coral-implementation-recipe.ipynb) and the coral ordinal notebook written by [Chris Kennedy and Stephen Matthews](https://github.com/ck37/coral-ordinal)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QsCIIgoFOkr"
      },
      "source": [
        "## Installation\n",
        "\n",
        "With pip you can either install the latest source code from GitHub or the stable version of the module on pypi.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#upgrade sklearn...only needed for advanced ordinalEncoder behaviours\n",
        "!pip install scikit-learn==0.24.2\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from scipy import special\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "from urllib.request import urlopen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO9cwoJ33G2q",
        "outputId": "9307fd1e-d4ce-4c23-f5f8-427f8713b579"
      },
      "source": [
        "GITHUB_AUTH = \"GarrettJenkinson:<APIaccessTOKEN>\"\n",
        "!git clone https://$GITHUB_AUTH@github.com/GarrettJenkinson/condor_tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWwEuq1E1gql",
        "outputId": "3d3d74d9-791d-4b88-8b8d-16973b1fe119"
      },
      "source": [
        "# Install source package from GitHub\n",
        "!pip install --force-reinstall --no-deps --use-feature=in-tree-build condor_tensorflow/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xemf4TAtrJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059ed231-319a-4c49-aae1-abe26289fcf3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version\", tf.__version__)\n",
        "\n",
        "import condor_tensorflow as condor\n",
        "print(\"CORAL Ordinal version:\", condor.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq0mT2yYucrx"
      },
      "source": [
        "## MNIST toy example\n",
        "\n",
        "This outcome is not actually ordinal, it's categorical. We're just using it as a toy example to show how the different components are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSOcGJBJG1Tr"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 1 # Not yet used\n",
        "learning_rate = 0.05\n",
        "batch_size = 128\n",
        "num_epochs = 2\n",
        "\n",
        "# Architecture\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooIWGJbGR2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d75e93d-f2b4-41dd-aef1-85064ee1de97"
      },
      "source": [
        "# Fetch and format the mnist data\n",
        "(mnist_images, mnist_labels), (mnist_images_test, mnist_labels_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Split off a validation dataset for early stopping\n",
        "mnist_images, mnist_images_val, mnist_labels, mnist_labels_val = \\\n",
        "  model_selection.train_test_split(mnist_images, mnist_labels, test_size = 5000, random_state = 1)\n",
        "\n",
        "print(\"Shape of training images:\", mnist_images.shape)\n",
        "print(\"Shape of training labels:\", mnist_labels.shape)\n",
        "\n",
        "print(\"Shape of test images:\", mnist_images_test.shape)\n",
        "print(\"Shape of test labels:\", mnist_labels_test.shape)\n",
        "\n",
        "print(\"Shape of validation images:\", mnist_images_val.shape)\n",
        "print(\"Shape of validation labels:\", mnist_labels_val.shape)\n",
        "\n",
        "# Also rescales to 0-1 range.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels, tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images_test[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels_test, tf.int64)))\n",
        "#test_dataset = test_dataset.shuffle(1000).batch(batch_size)\n",
        "# Here we do not shuffle the test dataset.\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images_val[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels_val, tf.int64)))\n",
        "val_dataset = val_dataset.shuffle(1000).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAg-gWZED1mR"
      },
      "source": [
        "### Simple MLP model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9MF55Xz53rx"
      },
      "source": [
        "Now we create a simple multi-layer perceptron model so that we can apply the ordinal output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ozv44W52Ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8751ccb-e887-44e5-ef71-54e4578d2096"
      },
      "source": [
        "def create_model(num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape = (28, 28, )))\n",
        "  model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(32, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  # No activation function specified so this will output cumulative logits.\n",
        "  model.add(tf.keras.layers.Dense(num_classes-1))\n",
        "  return model\n",
        "\n",
        "model = create_model(NUM_CLASSES)\n",
        "\n",
        "# Note that the model generates 1 fewer outputs than the number of classes. \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YAftcr9wxTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24548743-3ac5-4dc0-a8c2-3ea83c576477"
      },
      "source": [
        "# Or a functional API version\n",
        "def create_model2(num_classes):\n",
        "  inputs = tf.keras.Input(shape = (28, 28, ))\n",
        "\n",
        "  x = tf.keras.layers.Flatten()(inputs)\n",
        "  x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  x = tf.keras.layers.Dense(32, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "  # No activation function specified so this will output cumulative logits.\n",
        "  outputs = tf.keras.layers.Dense(num_classes-1)(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model2(NUM_CLASSES)\n",
        "\n",
        "# Note that the model generates 1 fewer outputs than the number of classes. \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUIADdPeF2w6"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "              loss = condor.SparseCondorOrdinalCrossEntropy(num_classes=NUM_CLASSES),\n",
        "              metrics = [condor.SparseOrdinalEarthMoversDistance(),\n",
        "                         condor.SparseOrdinalMeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as_rVDyAJurK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ec32f4-d1b4-424c-bf6e-8524643d6c14"
      },
      "source": [
        "%%time\n",
        "\n",
        "# This takes about 5 minutes on CPU, 2.5 minutes on GPU.\n",
        "history = model.fit(dataset, epochs = 5, validation_data = val_dataset,\n",
        "                    callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i--Xhzu8D6Mb"
      },
      "source": [
        "### Test set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epv3NVRmJ1gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dc7b3c-68a3-4d0c-d367-d6dbb6923250"
      },
      "source": [
        "# Evaluate on test dataset.\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfaK4doXvcS"
      },
      "source": [
        "### Cumulative logits to probabilities\n",
        "\n",
        "We can convert the cumulative logit output of the layer into the probability estimate for each ordinal label. This can then be used to calculate other metrics like accuracy or mean absolute error.\n",
        "\n",
        "Notice that the probability distribution for each observation is unimodal, which is what we want for an ordinal outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MAi4QxZyA2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c856b16a-a015-4c65-a32c-b0d897120d91"
      },
      "source": [
        "print(\"Predict on test dataset\")\n",
        "\n",
        "# Note that these are ordinal (cumulative) logits, not probabilities or regular logits.\n",
        "ordinal_logits = model.predict(test_dataset)\n",
        "\n",
        "# Convert from logits to label probabilities. This is initially a tensorflow tensor.\n",
        "tensor_probs = condor.ordinal_softmax(ordinal_logits)\n",
        "\n",
        "# Convert the tensor into a pandas dataframe.\n",
        "probs_df = pd.DataFrame(tensor_probs.numpy())\n",
        "\n",
        "probs_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuFGIJZvymSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846f85cb-331d-4e9d-e82a-c3992ba7b1a8"
      },
      "source": [
        "# Check that probabilities all sum to 1 - looks good!\n",
        "probs_df.sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZmVlStOItF8"
      },
      "source": [
        "### Label prediction\n",
        "\n",
        "This notebook shows two ways of calculating predicted labels. We can take the highest probability label (first method) or we can choose the highest label with Pr(Y > label) > 50%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA344vSf782T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442ae806-a019-49c8-80ce-6d37fbc40484"
      },
      "source": [
        "# Probs to labels\n",
        "labels = probs_df.idxmax(axis = 1)\n",
        "labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Bbs1tb8uh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74f210e-4801-4b89-f6d9-1570edb30e0f"
      },
      "source": [
        "# What is our accuracy? Around 69%.\n",
        "np.mean(labels == mnist_labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAUaY171_c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bdfbd060-0e8c-47df-e0d9-2048cdbd0e1a"
      },
      "source": [
        "# Compare to logit-based cumulative probs\n",
        "cum_probs = pd.DataFrame(ordinal_logits).apply(special.expit).cumprod(axis=1)\n",
        "cum_probs.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ67xh03JOii"
      },
      "source": [
        "Now we should try another option, which is used in the Cao et al. paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNKZU84UBE7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0702f534-b2bc-4142-ac19-d5baccffedbd"
      },
      "source": [
        "# Calculate the labels using the style of Cao et al.\n",
        "labels2 = cum_probs.apply(lambda x: x > 0.5).sum(axis = 1)\n",
        "labels2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-7BfbYBqSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e3a654-1a23-4583-c51a-95fa8b52549b"
      },
      "source": [
        "# What is the accuracy of these labels? \n",
        "np.mean(labels2 == mnist_labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGlY8HecDFPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6569bb0-a815-4abc-8b04-da8e19356124"
      },
      "source": [
        "# More often than not these are the same, but still a lot of discrepancy.\n",
        "np.mean(labels == labels2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OemBBdUmI6TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d800914f-4a56-4e19-d39b-deb1d79ee7da"
      },
      "source": [
        "print(\"Mean absolute label error version 1:\", np.mean(np.abs(labels - mnist_labels_test)))\n",
        "print(\"Mean absolute label error version 2:\", np.mean(np.abs(labels2 - mnist_labels_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCnAaNG_GSTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4063844-97cd-47cb-c00e-dbfebef48534"
      },
      "source": [
        "mnist_labels_test[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DpYEPQI6-gW"
      },
      "source": [
        "### Importance weights customization\n",
        "\n",
        "A quick example to show how the importance weights can be customized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STwPQdgHNne4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e32e75d-8e98-4b7e-8046-2d57d67e906a"
      },
      "source": [
        "model = create_model(num_classes = NUM_CLASSES)\n",
        "model.summary()\n",
        "\n",
        "# We have num_classes - 1 outputs (cumulative logits), so there are 9 elements\n",
        "# in the importance vector to customize.\n",
        "importance_weights = [1., 1., 0.5, 0.5, 0.5, 1., 1., 0.1, 0.1]\n",
        "loss_fn = condor.SparseCondorOrdinalCrossEntropy(NUM_CLASSES, importance_weights = importance_weights)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(lr = learning_rate), loss = loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73UOIams7TI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881954e6-01bc-4f31-a1a8-459d07ad98a3"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(dataset, epochs = num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJSm-gbwxTKt"
      },
      "source": [
        "## Amazon reviews and 5-star ratings\n",
        "\n",
        "Amazon review data via https://nijianmo.github.io/amazon/index.html#subsets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdEFFwfoZL_"
      },
      "source": [
        "!wget -qq http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Prime_Pantry_5.json.gz "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHiq67ioiUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9352a8-c6f0-4acb-9d14-5aa3b73a5f6a"
      },
      "source": [
        "data = []\n",
        "with gzip.open('Prime_Pantry_5.json.gz') as f:\n",
        "    for l in f:\n",
        "        data.append(json.loads(l.strip()))\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df = df[['overall', 'reviewText']]\n",
        "\n",
        "# There is a large amount of duplicate text in here, possibly due to paid/fraudulent reviews.\n",
        "df.drop_duplicates(\"reviewText\", inplace = True)\n",
        "\n",
        "# Some of the text is blank, which causes an obscure error about floating point conversion.\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "print(len(df))\n",
        "print(df.head())\n",
        "\n",
        "outcome_col = \"overall\"\n",
        "text_col = \"reviewText\"\n",
        "\n",
        "# We subtract the minimum value from the outcomes so that they start at 0.\n",
        "df[outcome_col] = df[outcome_col].values - df[outcome_col].min()\n",
        "\n",
        "print(\"\\n\", df.overall.value_counts())\n",
        "\n",
        "# TODO: define automatically based on the number of unique values in the outcome variable.\n",
        "num_classes = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrGlqgv7tv0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc47e862-ff48-4d0e-bcc4-e3e24951ad12"
      },
      "source": [
        "# Train/Test split\n",
        "text_train, text_test, labels_train, labels_test = \\\n",
        "  train_test_split(df[text_col].values, df[outcome_col].values, test_size = 10000, random_state = 1)\n",
        "\n",
        "print(\"Training text shape:\", text_train.shape)\n",
        "print(\"Training labels shape:\", labels_train.shape)\n",
        "print(\"Testing text shape:\", text_test.shape)\n",
        "print(\"Testing labels shape:\", labels_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF48EdMZuTxk"
      },
      "source": [
        "### Universal Sentence Encoder model (minimal code changes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOqeIkoJuWcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebfc6f3-8a36-4f7d-ad7e-4f712fb147ce"
      },
      "source": [
        "%%time\n",
        "# This takes 20 - 30 seconds.\n",
        "\n",
        "# Clear our GPU memory to stay efficient.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_text = tf.keras.layers.Input(shape = [], dtype = tf.string, name = 'input_text')\n",
        "\n",
        "model_url = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "\n",
        "base_model = hub.KerasLayer(model_url, input_shape = [],\n",
        "                            dtype = tf.string,\n",
        "                            trainable = False)\n",
        "                            \n",
        "embedded = base_model(input_text)\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation = 'relu')(embedded)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "output =tf.keras.layers.Dense(num_classes-1)(x) \n",
        "\n",
        "model = tf.keras.Model(inputs = input_text, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmMr5L_u_o64"
      },
      "source": [
        "model.compile(loss = condor.SparseCondorOrdinalCrossEntropy(num_classes=num_classes),\n",
        "              metrics = [condor.SparseOrdinalEarthMoversDistance(),\n",
        "                         condor.SparseOrdinalMeanAbsoluteError()],\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwNLAJg33tc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96a180e-cc73-458f-bad5-0e1ed30040b2"
      },
      "source": [
        "# Encode a test string and take a look at the first ten dimensions.\n",
        "base_model(np.array([\"test_string\"])).numpy()[0, :10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85MsPnRTxPEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6a8187-7aaa-4148-83ca-2b582b23e972"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(x = text_train,\n",
        "                    y = labels_train,\n",
        "                    epochs = 5,\n",
        "                    batch_size = 32, \n",
        "                    validation_split = 0.2,\n",
        "                    callbacks = [tf.keras.callbacks.EarlyStopping(patience = 2,\n",
        "                                                                  min_delta = 0.001,\n",
        "                                                                  restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFi2qXPlehY"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ocFVWnldzF"
      },
      "source": [
        "# For comparison, CORAL achieves loss 0.7962, MAE 0.3195\n",
        "model.evaluate(text_test, labels_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSBmDgXxkFb"
      },
      "source": [
        "# Generate predictions - initially these are cumulative logits.\n",
        "preds = model.predict(text_test)\n",
        "print(preds)\n",
        "# Convert cumulative logits to probabilities for each class aka rank or label.\n",
        "probs = pd.DataFrame(condor.ordinal_softmax(preds).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvD7ak27yA26"
      },
      "source": [
        "print(probs.head(10))\n",
        "print(labels_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNYR4nOjDJt_"
      },
      "source": [
        "#### Evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZzpmNSGxmJv"
      },
      "source": [
        "# Evaluate accuracy and mean absolute error\n",
        "labels_v1 = probs.idxmax(axis = 1)\n",
        "print(\"Accuracy of label version 1:\", np.mean(labels_v1 == labels_test))\n",
        "\n",
        "# Compare to logit-based cumulative probs\n",
        "cum_probs = pd.DataFrame(preds).apply(special.expit).cumprod(axis=1)\n",
        "# Calculate the labels using the style of Cao et al.\n",
        "labels_v2 = cum_probs.apply(lambda x: x > 0.5).sum(axis = 1)\n",
        "print(\"Accuracy of label version 2:\", np.mean(labels_v2 == labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYKpSMosDMuq"
      },
      "source": [
        "#### Evaluate mean absolute label error\n",
        "\n",
        "This is effectively an ordinal version of 1 - accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJZNCzwfGqC0"
      },
      "source": [
        "# These do not correspond with what we get from the model evaluation. Something must be off in one of these.\n",
        "print(\"Mean absolute label error version 1:\", np.mean(np.abs(labels_v1 - labels_test)))\n",
        "print(\"Mean absolute label error version 2:\", np.mean(np.abs(labels_v2 - labels_test)))\n",
        "\n",
        "print(\"Root mean squared label error version 1:\", np.sqrt(np.mean(np.square(labels_v1 - labels_test))))\n",
        "print(\"Root mean squared label error version 2:\", np.sqrt(np.mean(np.square(labels_v2 - labels_test))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSncBedI37-"
      },
      "source": [
        "# Review how absolute error is calculated for ordinal labels:\n",
        "pd.DataFrame({\"true\": labels_test, \"pred_v2\": labels_v1, \"abs\": labels_v2 - labels_test}).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUyJw-20B2AU"
      },
      "source": [
        "### Universal Sentence Encoder model (speed up using encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnCkqHv5CA_x"
      },
      "source": [
        "The \"Sparse\" versions of the CONDOR API are convenient and require minimal code changes. However there is a performance overhead compared to if we pre-encode the labels using CONDORs ordinal encoder. The sparse API is basically encoding on the fly inside the training loop. \n",
        "\n",
        "Also as we will see later, the labels do not always come encoded as 0,1,...,K-1. In this case, using the CondorOrdinalEncoder will help transform labels into ordinal-ready values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq1aA2ffB2Ai"
      },
      "source": [
        "%%time\n",
        "# pre-encoding runs very fast so the savings later are worth it\n",
        "enc = condor.CondorOrdinalEncoder(nclasses=num_classes)\n",
        "enc_labs_train = enc.fit_transform(labels_train)\n",
        "enc_labs_test = enc.transform(labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRP7kkPB2Ai"
      },
      "source": [
        "# Note the lack of \"Sparse\" in the condor functions here\n",
        "model.compile(loss = condor.CondorOrdinalCrossEntropy(num_classes=num_classes),\n",
        "              metrics = [condor.OrdinalEarthMoversDistance(),\n",
        "                         condor.OrdinalMeanAbsoluteError()],\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb2NU9kVB2Ai"
      },
      "source": [
        "%%time\n",
        "# note the encoded labels are passed to the fit now\n",
        "history = model.fit(x = text_train,\n",
        "                    y = enc_labs_train,\n",
        "                    epochs = 5,\n",
        "                    batch_size = 32, \n",
        "                    validation_split = 0.2,\n",
        "                    callbacks = [tf.keras.callbacks.EarlyStopping(patience = 2,\n",
        "                                                                  min_delta = 0.001,\n",
        "                                                                  restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWBl7PuZB2Ai"
      },
      "source": [
        "model.evaluate(text_test, enc_labs_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt9mAOqvE4Ep"
      },
      "source": [
        "#### More examples of label encoding capabilities\n",
        "Here we demo the features of the ordinal encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGcYAoi0E_FI"
      },
      "source": [
        "# Here the ordinal encoder figures out how many classes there are automatically\n",
        "# and orders them in the default sklearn OrdinalEncoder fashion \n",
        "# (i.e., alphabetically here)\n",
        "labels = np.array(['a','b','c','d','e'])\n",
        "enc_labs = condor.CondorOrdinalEncoder().fit_transform(labels)\n",
        "print(enc_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YuSAf1wFgAq"
      },
      "source": [
        "# Here the ordinal encoder figures out how many classes there are automatically\n",
        "# and orders them in the default sklearn OrdinalEncoder fashion \n",
        "# (i.e., alphabetically here). This time it is dealing with a basic list.\n",
        "labels = ['a','b','c','d','e']\n",
        "enc_labs = condor.CondorOrdinalEncoder().fit_transform(labels)\n",
        "\n",
        "print(enc_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkzccbsjFwdv"
      },
      "source": [
        "# Here we wish to specify the order to be different from alphabetical. Note\n",
        "# this would also allow \"missing\" categories to be included in proper order.\n",
        "labels = ['low','med','high']\n",
        "enc = condor.CondorOrdinalEncoder(categories=[['low', 'med', 'high']])\n",
        "enc_labs = enc.fit_transform(labels)\n",
        "\n",
        "print(enc_labs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}